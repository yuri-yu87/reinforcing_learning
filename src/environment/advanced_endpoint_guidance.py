"""
é«˜çº§ç»ˆç‚¹å¼•å¯¼å¥–åŠ±ç³»ç»Ÿ
é’ˆå¯¹6é˜¶æ®µè¯¾ç¨‹å­¦ä¹ è¿›è¡Œç²¾ç»†è°ƒä¼˜ï¼Œç¡®ä¿UAVåœ¨è®¿é—®å®Œç”¨æˆ·åå¼ºçƒˆå€¾å‘äºå‰å¾€ç»ˆç‚¹
"""

from dataclasses import dataclass
from typing import Dict, Any, List, Optional, Tuple
import numpy as np


@dataclass
class AdvancedEndpointGuidanceConfig:
    """
    é«˜çº§ç»ˆç‚¹å¼•å¯¼é…ç½®
    ä¸“ä¸ºè§£å†³"UAVè®¿é—®å®Œç”¨æˆ·ä½†ä¸å»ç»ˆç‚¹"çš„é—®é¢˜è®¾è®¡
    """
    
    # === åŸºç¡€å¥–åŠ±æƒé‡ ===
    w_throughput_base: float = 100.0
    w_movement_bonus: float = 15.0
    
    # === ç”¨æˆ·è®¿é—®å¥–åŠ±ï¼ˆé€’å‡ç­–ç•¥ï¼‰===
    B_user_visit_base: float = 3000.0      # åŸºç¡€å•ç”¨æˆ·è®¿é—®å¥–åŠ±
    B_user_visit_decay: float = 0.8        # åç»­ç”¨æˆ·å¥–åŠ±è¡°å‡å› å­
    B_all_users_visited: float = 8000.0    # å…¨ç”¨æˆ·è®¿é—®å®Œæˆå¥–åŠ±
    B_sequential_bonus: float = 2000.0     # é¡ºåºè®¿é—®å¥–åŠ±
    
    # === ç»ˆç‚¹å¼•å¯¼å¥–åŠ±ï¼ˆå¤§å¹…å¢å¼ºï¼‰===
    B_reach_end_base: float = 6000.0           # åŸºç¡€åˆ°è¾¾ç»ˆç‚¹å¥–åŠ±
    B_mission_complete: float = 15000.0         # å®Œæ•´ä»»åŠ¡å®Œæˆå¥–åŠ±
    
    # === åŠ¨æ€ç»ˆç‚¹å¼•å¯¼æœºåˆ¶ ===
    w_end_approach_base: float = 200.0          # åŸºç¡€ç»ˆç‚¹æ¥è¿‘æƒé‡
    w_end_urgency_multiplier: float = 5.0       # è®¿é—®å®Œç”¨æˆ·åçš„ç´§è¿«åº¦å€æ•°
    w_end_progress_base: float = 100.0          # åŸºç¡€ç»ˆç‚¹è¿›å±•æƒé‡
    w_end_progress_multiplier: float = 8.0      # è®¿é—®å®Œç”¨æˆ·åçš„è¿›å±•å€æ•°
    
    # === æ™ºèƒ½æƒ©ç½šæœºåˆ¶ ===
    penalty_incomplete_mission: float = 2000.0  # æœªå®Œæˆä»»åŠ¡çš„æŒç»­æƒ©ç½š
    penalty_wasted_time: float = 50.0           # è®¿é—®å®Œç”¨æˆ·åçš„æ—¶é—´æµªè´¹æƒ©ç½š
    penalty_distance_from_end: float = 100.0    # è®¿é—®å®Œç”¨æˆ·åè¿œç¦»ç»ˆç‚¹çš„æƒ©ç½š
    
    # === æœåŠ¡å‚æ•° ===
    user_service_radius: float = 60.0
    close_to_user_threshold: float = 80.0
    end_position_tolerance: float = 25.0
    user_visit_time_threshold: float = 0.8
    
    # === æ—¶é—´çº¦æŸ ===
    min_flight_time: float = 200.0
    max_flight_time: float = 300.0
    time_step: float = 0.1
    
    # === å¼•å¯¼é˜ˆå€¼ ===
    end_guidance_activation_distance: float = 150.0   # ç»ˆç‚¹å¼•å¯¼æ¿€æ´»è·ç¦»
    strong_guidance_activation_distance: float = 80.0  # å¼ºå¼•å¯¼æ¿€æ´»è·ç¦»
    
    # === å…¶ä»–å‚æ•° ===
    stagnation_threshold: float = 1.0
    stagnation_time_window: float = 3.0
    w_stagnation: float = 5.0
    w_oob: float = 100.0
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert config to dictionary"""
        return {
            'B_user_visit_base': self.B_user_visit_base,
            'B_all_users_visited': self.B_all_users_visited,
            'B_reach_end_base': self.B_reach_end_base,
            'B_mission_complete': self.B_mission_complete,
            'w_end_approach_base': self.w_end_approach_base,
            'w_end_urgency_multiplier': self.w_end_urgency_multiplier,
            'penalty_incomplete_mission': self.penalty_incomplete_mission,
            'user_service_radius': self.user_service_radius,
            'end_position_tolerance': self.end_position_tolerance
        }


class AdvancedEndpointGuidanceCalculator:
    """
    é«˜çº§ç»ˆç‚¹å¼•å¯¼å¥–åŠ±è®¡ç®—å™¨
    å®ç°æ™ºèƒ½åŒ–ã€è‡ªé€‚åº”çš„ç»ˆç‚¹å¼•å¯¼æœºåˆ¶
    """
    
    def __init__(self, config: AdvancedEndpointGuidanceConfig, stage_manager=None):
        self.config = config
        self.stage_manager = stage_manager
        self.reset()
    
    def reset(self):
        """é‡ç½®è®¡ç®—å™¨çŠ¶æ€"""
        # ç”¨æˆ·è®¿é—®è·Ÿè¸ª
        self.user_visit_times = {}
        self.user_visited_flags = set()
        self.user_visit_order = []
        
        # ä½ç½®å’ŒçŠ¶æ€è·Ÿè¸ª
        self.position_history = []
        self.time_history = []
        self.previous_position = None
        self.last_target_distances = {}
        
        # ç»ˆç‚¹å¼•å¯¼çŠ¶æ€
        self.all_users_visited = False
        self.all_users_visited_time = None
        self.end_guidance_activated = False
        self.strong_guidance_activated = False
        
        # æ€§èƒ½è·Ÿè¸ª
        self.time_since_all_users_visited = 0.0
        self.mission_completed = False
    
    def calculate_reward(self, 
                        uav_position: np.ndarray,
                        end_position: np.ndarray,
                        user_positions: np.ndarray,
                        user_throughputs: np.ndarray,
                        current_time: float,
                        current_speed: float,
                        env_bounds: tuple,
                        episode_done: bool,
                        reached_end: bool) -> Dict[str, float]:
        """
        é«˜çº§ç»ˆç‚¹å¼•å¯¼å¥–åŠ±è®¡ç®—
        """
        reward_breakdown = {}
        
        # è·å–å½“å‰é˜¶æ®µé…ç½®ï¼ˆå¦‚æœæœ‰stage_managerï¼‰
        if self.stage_manager:
            stage_config = self.stage_manager.get_stage_config(self.stage_manager.current_stage)
            effective_user_positions = stage_config['user_positions']
            stage_multipliers = stage_config['reward_multipliers']
        else:
            effective_user_positions = user_positions
            stage_multipliers = {'user_visit': 1.0, 'approach': 1.0, 'completion': 1.0}
        
        # === 1. åŸºç¡€ååé‡å¥–åŠ± ===
        throughput_reward = self.config.w_throughput_base * np.sum(user_throughputs)
        reward_breakdown['throughput'] = throughput_reward
        
        # === 2. ç§»åŠ¨å¥–åŠ± ===
        movement_reward = 0.0
        if self.previous_position is not None:
            displacement = np.linalg.norm(uav_position - self.previous_position)
            movement_reward = self.config.w_movement_bonus * min(displacement / 3.0, 1.0)
        reward_breakdown['movement'] = movement_reward
        
        # === 3. ç”¨æˆ·è®¿é—®å¤„ç†å’Œå¥–åŠ± ===
        visit_rewards = self._update_user_visits_and_calculate_rewards(
            uav_position, effective_user_positions, current_time, stage_multipliers
        )
        reward_breakdown.update(visit_rewards)
        
        # === 4. æ™ºèƒ½ç»ˆç‚¹å¼•å¯¼æœºåˆ¶ ===
        guidance_rewards = self._calculate_advanced_endpoint_guidance(
            uav_position, end_position, effective_user_positions, current_time
        )
        reward_breakdown.update(guidance_rewards)
        
        # === 5. è¿›å±•å¥–åŠ±ï¼ˆè‡ªé€‚åº”ï¼‰ ===
        progress_rewards = self._calculate_adaptive_progress_rewards(
            uav_position, effective_user_positions, end_position
        )
        reward_breakdown.update(progress_rewards)
        
        # === 6. æ™ºèƒ½æƒ©ç½šæœºåˆ¶ ===
        penalties = self._calculate_intelligent_penalties(
            uav_position, end_position, env_bounds, current_time
        )
        reward_breakdown.update(penalties)
        
        # === 7. ç»ˆç«¯å¥–åŠ±ï¼ˆå¢å¼ºï¼‰ ===
        if episode_done:
            terminal_rewards = self._calculate_enhanced_terminal_rewards(
                reached_end, current_time, len(effective_user_positions), stage_multipliers
            )
            reward_breakdown.update(terminal_rewards)
        
        # === 8. è®¡ç®—æ€»å¥–åŠ± ===
        total_reward = sum(reward_breakdown.values())
        reward_breakdown['total'] = total_reward
        
        # === 9. æ›´æ–°çŠ¶æ€ ===
        self._update_internal_state(uav_position, effective_user_positions, end_position, current_time)
        
        return reward_breakdown
    
    def _update_user_visits_and_calculate_rewards(self, uav_position: np.ndarray, 
                                                 user_positions: np.ndarray, current_time: float,
                                                 multipliers: Dict[str, float]) -> Dict[str, float]:
        """æ›´æ–°ç”¨æˆ·è®¿é—®å¹¶è®¡ç®—é€’å‡å¥–åŠ±"""
        rewards = {
            'user_visit_bonus': 0.0
        }
        
        # åªå¤„ç†æœ‰æ•ˆç”¨æˆ·
        for user_id, user_pos in enumerate(user_positions):
            distance = np.linalg.norm(uav_position - user_pos)
            
            # åœ¨æœåŠ¡åŠå¾„å†…ç´¯ç§¯è®¿é—®æ—¶é—´
            if distance <= self.config.user_service_radius:
                if user_id not in self.user_visit_times:
                    self.user_visit_times[user_id] = 0.0
                self.user_visit_times[user_id] += self.config.time_step
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆè®¿é—®
                if (self.user_visit_times[user_id] >= self.config.user_visit_time_threshold and
                    user_id not in self.user_visited_flags):
                    
                    self.user_visited_flags.add(user_id)
                    self.user_visit_order.append(user_id)
                    
                    # === é€’å‡è®¿é—®å¥–åŠ±æœºåˆ¶ ===
                    visit_count = len(self.user_visited_flags)
                    
                    # åŸºç¡€å¥–åŠ±éšè®¿é—®é¡ºåºé€’å‡
                    decay_factor = self.config.B_user_visit_decay ** (visit_count - 1)
                    base_visit_reward = self.config.B_user_visit_base * decay_factor * multipliers['user_visit']
                    
                    # é¡ºåºå¥–åŠ±ï¼ˆé¼“åŠ±è¿ç»­è®¿é—®ï¼‰
                    if visit_count > 1:
                        sequential_reward = self.config.B_sequential_bonus * 0.5
                        base_visit_reward += sequential_reward
                    
                    rewards['user_visit_bonus'] += base_visit_reward
                    
                    print(f"ğŸ¯ ç”¨æˆ·{user_id}è®¿é—®å®Œæˆï¼è·å¾—{base_visit_reward:.0f}å¥–åŠ±ï¼ˆç¬¬{visit_count}ä¸ªï¼‰")
                    
                    # === å…¨ç”¨æˆ·è®¿é—®å®Œæˆå¥–åŠ± ===
                    if len(self.user_visited_flags) == len(user_positions):
                        all_users_reward = self.config.B_all_users_visited
                        rewards['user_visit_bonus'] += all_users_reward
                        
                        # è®°å½•å®Œæˆæ—¶é—´ï¼Œæ¿€æ´»ç»ˆç‚¹å¼•å¯¼
                        if not self.all_users_visited:
                            self.all_users_visited = True
                            self.all_users_visited_time = current_time
                            self.end_guidance_activated = True
                            print(f"ğŸ† å…¨ç”¨æˆ·è®¿é—®å®Œæˆï¼æ¿€æ´»ç»ˆç‚¹å¼•å¯¼æœºåˆ¶ï¼è·å¾—{all_users_reward:.0f}é¢å¤–å¥–åŠ±")
        
        return rewards
    
    def _calculate_advanced_endpoint_guidance(self, uav_position: np.ndarray, 
                                            end_position: np.ndarray, user_positions: np.ndarray,
                                            current_time: float) -> Dict[str, float]:
        """é«˜çº§ç»ˆç‚¹å¼•å¯¼æœºåˆ¶"""
        rewards = {
            'end_approach': 0.0,
            'end_urgency': 0.0,
            'end_magnetism': 0.0,
            'completion_drive': 0.0
        }
        
        distance_to_end = np.linalg.norm(uav_position - end_position)
        
        # === é˜¶æ®µ1ï¼šåŸºç¡€ç»ˆç‚¹å¼•å¯¼ï¼ˆè·ç¦»è¾ƒè¿œæ—¶ï¼‰ ===
        if distance_to_end <= self.config.end_guidance_activation_distance:
            base_proximity_factor = (self.config.end_guidance_activation_distance - distance_to_end) / self.config.end_guidance_activation_distance
            base_approach_reward = self.config.w_end_approach_base * base_proximity_factor * 0.2
            
            # æ ¹æ®ç”¨æˆ·è®¿é—®çŠ¶æ€è°ƒæ•´å¥–åŠ±
            users_visited = len(self.user_visited_flags)
            total_users = len(user_positions)
            
            if users_visited == total_users:
                # è®¿é—®å®Œæ‰€æœ‰ç”¨æˆ·ï¼šå…¨åŠŸç‡ç»ˆç‚¹å¼•å¯¼
                rewards['end_approach'] = base_approach_reward * self.config.w_end_urgency_multiplier
                
                # === é˜¶æ®µ2ï¼šå¼ºå¼•å¯¼æœºåˆ¶ï¼ˆè·ç¦»ä¸­ç­‰æ—¶ï¼‰ ===
                if distance_to_end <= self.config.strong_guidance_activation_distance:
                    if not self.strong_guidance_activated:
                        self.strong_guidance_activated = True
                        print("âš¡ æ¿€æ´»å¼ºç»ˆç‚¹å¼•å¯¼æœºåˆ¶ï¼")
                    
                    # å¼ºå¼•å¯¼å¥–åŠ±
                    strong_proximity_factor = (self.config.strong_guidance_activation_distance - distance_to_end) / self.config.strong_guidance_activation_distance
                    rewards['end_urgency'] = self.config.w_end_approach_base * strong_proximity_factor * self.config.w_end_urgency_multiplier * 2.0
                
                # === é˜¶æ®µ3ï¼šç£å¸æ•ˆåº”ï¼ˆè·ç¦»å¾ˆè¿‘æ—¶ï¼‰ ===
                if distance_to_end <= 40.0:
                    magnetism_factor = (40.0 - distance_to_end) / 40.0
                    magnetism_reward = self.config.w_end_approach_base * magnetism_factor * magnetism_factor * 10.0
                    rewards['end_magnetism'] = magnetism_reward
                
                # === æŒç»­å®Œæˆé©±åŠ¨åŠ› ===
                if self.all_users_visited_time is not None:
                    time_since_completion = current_time - self.all_users_visited_time
                    # æ—¶é—´è¶Šé•¿ï¼Œé©±åŠ¨åŠ›è¶Šå¼ºï¼ˆé¿å…æµªè´¹æ—¶é—´ï¼‰
                    time_urgency = min(time_since_completion / 20.0, 5.0)  # æœ€å¤š5å€
                    completion_drive = self.config.w_end_approach_base * time_urgency * 2.0
                    rewards['completion_drive'] = completion_drive
                    
            elif users_visited > 0:
                # è®¿é—®äº†éƒ¨åˆ†ç”¨æˆ·ï¼šä¸­ç­‰ç»ˆç‚¹å¼•å¯¼
                completion_ratio = users_visited / total_users
                rewards['end_approach'] = base_approach_reward * completion_ratio * 0.3
            else:
                # æ²¡æœ‰è®¿é—®ç”¨æˆ·ï¼šå¾®å¼±ç»ˆç‚¹å¼•å¯¼ï¼ˆé¿å…ç›´æ¥å»ç»ˆç‚¹ï¼‰
                rewards['end_approach'] = base_approach_reward * 0.05
        
        return rewards
    
    def _calculate_adaptive_progress_rewards(self, uav_position: np.ndarray, 
                                           user_positions: np.ndarray, end_position: np.ndarray) -> Dict[str, float]:
        """è‡ªé€‚åº”è¿›å±•å¥–åŠ±"""
        rewards = {
            'user_progress': 0.0,
            'end_progress': 0.0,
            'super_end_progress': 0.0
        }
        
        # è®¡ç®—å½“å‰è·ç¦»
        current_distances = {}
        
        # åˆ°æœªè®¿é—®ç”¨æˆ·çš„è·ç¦»
        for i, user_pos in enumerate(user_positions):
            if i not in self.user_visited_flags:
                current_distances[f'user_{i}'] = np.linalg.norm(uav_position - user_pos)
        
        # åˆ°ç»ˆç‚¹çš„è·ç¦»
        end_distance = np.linalg.norm(uav_position - end_position)
        current_distances['end'] = end_distance
        
        # è®¡ç®—è¿›å±•å¥–åŠ±
        for target, current_dist in current_distances.items():
            if target in self.last_target_distances:
                last_dist = self.last_target_distances[target]
                progress = last_dist - current_dist
                
                if progress > 0:  # è·ç¦»å‡å°‘äº†
                    if target == 'end':
                        # === ç»ˆç‚¹è¿›å±•å¥–åŠ±ï¼ˆè‡ªé€‚åº”å¢å¼ºï¼‰===
                        base_reward = self.config.w_end_progress_base * progress * 0.3
                        
                        if self.all_users_visited:
                            # è®¿é—®å®Œæ‰€æœ‰ç”¨æˆ·åï¼Œç»ˆç‚¹è¿›å±•å¥–åŠ±å¤§å¹…å¢å¼º
                            enhanced_reward = base_reward * self.config.w_end_progress_multiplier
                            rewards['end_progress'] = enhanced_reward
                            
                            # è¶…çº§è¿›å±•å¥–åŠ±ï¼ˆè·ç¦»å¾ˆè¿‘æ—¶ï¼‰
                            if current_dist <= 50.0:
                                super_bonus = self.config.w_end_progress_base * progress * 5.0
                                rewards['super_end_progress'] = super_bonus
                        else:
                            rewards['end_progress'] = base_reward * 0.2
                    else:
                        # ç”¨æˆ·è¿›å±•å¥–åŠ±
                        rewards['user_progress'] += self.config.w_end_progress_base * progress * 0.15
        
        # æ›´æ–°è·ç¦»è®°å½•
        self.last_target_distances = current_distances
        
        return rewards
    
    def _calculate_intelligent_penalties(self, uav_position: np.ndarray, 
                                       end_position: np.ndarray, env_bounds: tuple,
                                       current_time: float) -> Dict[str, float]:
        """æ™ºèƒ½æƒ©ç½šæœºåˆ¶"""
        penalties = {
            'oob_penalty': 0.0,
            'stagnation_penalty': 0.0,
            'time_waste_penalty': 0.0,
            'distance_penalty': 0.0,
            'incomplete_mission_penalty': 0.0
        }
        
        # 1. å‡ºç•Œæƒ©ç½š
        x_min, y_min, z_min = 0, 0, 0
        x_max, y_max, z_max = env_bounds
        if (uav_position[0] < x_min or uav_position[0] > x_max or
            uav_position[1] < y_min or uav_position[1] > y_max):
            penalties['oob_penalty'] = -self.config.w_oob
        
        # 2. åœæ»æƒ©ç½š
        stagnation_penalty = self._calculate_stagnation_penalty(uav_position, current_time)
        penalties['stagnation_penalty'] = -stagnation_penalty
        
        # 3. è®¿é—®å®Œç”¨æˆ·åçš„ç‰¹æ®Šæƒ©ç½š
        if self.all_users_visited:
            distance_to_end = np.linalg.norm(uav_position - end_position)
            
            # æ—¶é—´æµªè´¹æƒ©ç½š
            if self.all_users_visited_time is not None:
                time_wasted = current_time - self.all_users_visited_time
                if time_wasted > 5.0:  # è¶…è¿‡5ç§’æ²¡åˆ°ç»ˆç‚¹
                    time_penalty = self.config.penalty_wasted_time * (time_wasted - 5.0)
                    penalties['time_waste_penalty'] = -time_penalty
            
            # è·ç¦»æƒ©ç½šï¼ˆè·ç¦»ç»ˆç‚¹è¿‡è¿œçš„æŒç»­æƒ©ç½šï¼‰
            if distance_to_end > self.config.end_position_tolerance * 2:
                distance_penalty = self.config.penalty_distance_from_end * (distance_to_end / 100.0)
                penalties['distance_penalty'] = -distance_penalty
        
        # 4. æœªå®Œæˆä»»åŠ¡æŒç»­æƒ©ç½š
        if not self.all_users_visited or not self._check_reached_end(uav_position, end_position):
            incomplete_penalty = self.config.penalty_incomplete_mission * 0.01  # æ¯æ­¥å°æƒ©ç½š
            penalties['incomplete_mission_penalty'] = -incomplete_penalty
        
        return penalties
    
    def _calculate_enhanced_terminal_rewards(self, reached_end: bool, current_time: float, 
                                           num_users: int, multipliers: Dict[str, float]) -> Dict[str, float]:
        """å¢å¼ºç»ˆç«¯å¥–åŠ±"""
        rewards = {
            'terminal_reach_end': 0.0,
            'terminal_all_users': 0.0,
            'terminal_mission_complete': 0.0,
            'terminal_efficiency_bonus': 0.0
        }
        
        # åˆ°è¾¾ç»ˆç‚¹å¥–åŠ±
        if reached_end:
            rewards['terminal_reach_end'] = self.config.B_reach_end_base
        
        # è®¿é—®æ‰€æœ‰ç”¨æˆ·å¥–åŠ±
        if len(self.user_visited_flags) == num_users:
            rewards['terminal_all_users'] = self.config.B_all_users_visited
        
        # å®Œæ•´ä»»åŠ¡å¥–åŠ±
        if (reached_end and 
            len(self.user_visited_flags) == num_users and
            200.0 <= current_time <= 300.0):
            completion_reward = self.config.B_mission_complete * multipliers['completion']
            rewards['terminal_mission_complete'] = completion_reward
            
            # æ•ˆç‡å¥–åŠ±ï¼ˆæ›´å¿«å®Œæˆç»™äºˆé¢å¤–å¥–åŠ±ï¼‰
            if self.all_users_visited_time is not None:
                completion_time = current_time - self.all_users_visited_time
                if completion_time < 30.0:  # 30ç§’å†…å®Œæˆç»ˆç‚¹å¯¼èˆª
                    efficiency_bonus = (30.0 - completion_time) * 200.0
                    rewards['terminal_efficiency_bonus'] = efficiency_bonus
                    print(f"âš¡ æ•ˆç‡å¥–åŠ±ï¼{completion_time:.1f}ç§’å®Œæˆç»ˆç‚¹å¯¼èˆªï¼Œè·å¾—{efficiency_bonus:.0f}å¥–åŠ±")
            
            print(f"ğŸ† ä»»åŠ¡å®Œæˆï¼è·å¾—{completion_reward:.0f}å®Œæˆå¥–åŠ±")
        
        return rewards
    
    def _calculate_stagnation_penalty(self, uav_position: np.ndarray, current_time: float) -> float:
        """è®¡ç®—åœæ»æƒ©ç½š"""
        self.position_history.append(uav_position.copy())
        self.time_history.append(current_time)
        
        window_size = int(self.config.stagnation_time_window / self.config.time_step)
        if len(self.position_history) > window_size:
            self.position_history = self.position_history[-window_size:]
            self.time_history = self.time_history[-window_size:]
        
        if len(self.position_history) >= window_size:
            pos_variance = np.var(self.position_history, axis=0)
            total_variance = np.sum(pos_variance[:2])
            
            if total_variance < self.config.stagnation_threshold:
                # å¦‚æœè®¿é—®å®Œæ‰€æœ‰ç”¨æˆ·ï¼Œåœæ»æƒ©ç½šåŠ é‡
                if self.all_users_visited:
                    return self.config.w_stagnation * 3.0
                else:
                    return self.config.w_stagnation
        
        return 0.0
    
    def _check_reached_end(self, uav_position: np.ndarray, end_position: np.ndarray) -> bool:
        """æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç»ˆç‚¹"""
        distance = np.linalg.norm(uav_position - end_position)
        return distance <= self.config.end_position_tolerance
    
    def _update_internal_state(self, uav_position: np.ndarray, user_positions: np.ndarray,
                              end_position: np.ndarray, current_time: float):
        """æ›´æ–°å†…éƒ¨çŠ¶æ€"""
        self.previous_position = uav_position.copy()
        
        # æ›´æ–°è®¿é—®å®Œç”¨æˆ·åçš„æ—¶é—´è®¡æ•°
        if self.all_users_visited and self.all_users_visited_time is not None:
            self.time_since_all_users_visited = current_time - self.all_users_visited_time
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'user_visit_times': dict(self.user_visit_times),
            'user_visited_flags': list(self.user_visited_flags),
            'user_visit_order': self.user_visit_order.copy(),
            'users_visited': len(self.user_visited_flags),
            'all_users_visited': self.all_users_visited,
            'end_guidance_activated': self.end_guidance_activated,
            'strong_guidance_activated': self.strong_guidance_activated,
            'time_since_all_users_visited': self.time_since_all_users_visited,
            'mission_completed': self.mission_completed
        }
