"""
Reward Configuration for UAV Environment

This module defines reward parameters and configuration for the UAV environment.
Following the architectural principle: reward mechanism belongs to Environment layer.
"""

from dataclasses import dataclass
from typing import Dict, Any


@dataclass
class RewardConfig:
    """
    Reward system configuration for UAV environment.
    
    Implements the optimized reward formula:
    r = w_rate Â· normalize(sum_rate) + w_goal Â· [F(d_end(s')) - F(d_end(s))] 
        + w_fair Â· Î£ log(Îµ + service_i) - w_time Â· Î”t
    """
    
    # Main reward weights
    w_rate: float = 0.8                    # Throughput weight (main objective)
    w_goal: float = 0.5                    # Goal weight (only active after all users visited)
    w_fair: float = 1.0                    # Strong fairness weight (force user rotation)
    w_time: float = 0.01                   # Minimal time penalty
    
    # Normalization parameters
    max_expected_throughput: float = 20.0  # For throughput normalization (higher to avoid early saturation)
    distance_normalization: float = 50.0   # Distance normalization parameter (d0)
    fairness_epsilon: float = 1e-6        # Small value to avoid log(0)
    
    # Mission completion tolerance
    end_position_tolerance: float = 5.0    # Meters tolerance for mission completion
    # Terminal bonus when reaching the end location the first time in an episode
    terminal_bonus: float = 800.0          # High bonus for mission completion with all users visited
    # Per-step penalty for stagnating (hovering/no displacement) when far from end
    hover_penalty: float = 0.1
    
    # è®¿é—®è¡°å‡æœºåˆ¶ - è§£å†³å±€éƒ¨æœ€ä¼˜é—®é¢˜
    enable_visit_decay: bool = True         # æ˜¯å¦å¯ç”¨è®¿é—®è¡°å‡
    visit_decay_radius: float = 20.0        # ç”¨æˆ·è®¿é—®åŠå¾„(m)
    visit_decay_rate: float = 0.5           # è¡°å‡å€æ•°(0.5 = 50%è¡°å‡)
    visit_decay_threshold: float = 0.5      # è§¦å‘è¡°å‡çš„ç´¯ç§¯æœåŠ¡é‡
    
    # ç”¨æˆ·è®¿é—®å®Œæˆé—¨æ§æœºåˆ¶ - å¼ºåˆ¶è®¿é—®æ‰€æœ‰ç”¨æˆ·
    enable_visit_gating: bool = True
    min_visit_threshold: float = 2.0        # æ›´é«˜é˜ˆå€¼ï¼Œç¡®ä¿çœŸæ­£é è¿‘å¹¶æœåŠ¡è¿‡ç”¨æˆ·
    goal_reward_multiplier: float = 0.1     # æœªè®¿é—®å®Œæ‰€æœ‰ç”¨æˆ·æ—¶çš„ç›®æ ‡å¥–åŠ±å€æ•°
    visited_goal_multiplier: float = 5.0    # è®¿é—®å®Œæ‰€æœ‰ç”¨æˆ·åçš„ç›®æ ‡å¥–åŠ±å€æ•°
    
    # ç”¨æˆ·ä¸“æ³¨æœºåˆ¶ (æ”¹è¿›ç‰ˆ) - è·ç¦»+æ—¶é—´åŒé‡è®¿é—®åˆ¤å®š
    enable_user_focus: bool = True          # å¯ç”¨ç”¨æˆ·ä¸“æ³¨æœºåˆ¶
    
    # æ–°çš„è®¿é—®å®Œæˆåˆ¤å®šæ¡ä»¶ï¼šè·ç¦»+æ—¶é—´åŒé‡è¦æ±‚
    visit_distance_threshold: float = 5.0  # è®¿é—®è·ç¦»é˜ˆå€¼ï¼šå¿…é¡»åœ¨æ­¤è·ç¦»å†…
    visit_time_threshold: float = 5.0       # è®¿é—®æ—¶é—´é˜ˆå€¼ï¼šå¿…é¡»åœ¨è·ç¦»å†…åœç•™æ­¤æ—¶é—´ï¼ˆç§’ï¼‰
    
    # å¥–åŠ±æƒé‡
    focus_reward_multiplier: float = 1.0    # å½“å‰ä¸“æ³¨ç”¨æˆ·çš„ååé‡å¥–åŠ±å€æ•°
    non_focus_reward_multiplier: float = 0.0  # éä¸“æ³¨ç”¨æˆ·ååé‡å¥–åŠ±å€æ•°ï¼ˆæŒ‰è¦æ±‚è®¾ä¸º0ï¼‰
    visited_user_reward_multiplier: float = 0.0  # å·²è®¿é—®ç”¨æˆ·çš„ååé‡å¥–åŠ±å€æ•°
    per_user_completion_bonus: float = 100.0     # å®Œæˆå•ä¸ªç”¨æˆ·è®¿é—®çš„ä¸€æ¬¡æ€§å¥–åŠ±ï¼ˆé™ä½ï¼‰
    
    # è·ç¦»å¢é‡å¥–åŠ±æƒé‡ï¼ˆç±»ä¼¼w_rateï¼‰
    w_distance_approach: float = 1.0        # è·ç¦»æ¥è¿‘å¥–åŠ±æƒé‡ï¼Œä¸w_rateåŒç­‰é‡è¦
    
    # ä¸“æ³¨è·ç¦»åŠ¿å‡½æ•°å‚æ•°
    w_focus: float = 0.4                    # ä¸“æ³¨è·ç¦»åŠ¿å‡½æ•°æƒé‡
    focus_distance_normalization: float = 50.0  # è·ç¦»å½’ä¸€åŒ–å‚æ•° d0
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            'w_rate': self.w_rate,
            'w_goal': self.w_goal, 
            'w_fair': self.w_fair,
            'w_time': self.w_time,
            'max_expected_throughput': self.max_expected_throughput,
            'distance_normalization': self.distance_normalization,
            'fairness_epsilon': self.fairness_epsilon,
            'end_position_tolerance': self.end_position_tolerance,
            'terminal_bonus': self.terminal_bonus
        }
    
    @classmethod
    def from_dict(cls, config_dict: Dict[str, Any]) -> 'RewardConfig':
        """Create from dictionary."""
        return cls(**config_dict)
    
    @classmethod
    def get_high_throughput_config(cls) -> 'RewardConfig':
        """Configuration optimized for high throughput."""
        return cls(
            w_rate=1.5,      # Higher throughput weight
            w_goal=0.2,      # Lower goal weight
            w_fair=0.1,      # Lower fairness weight
            w_time=0.01
        )
    
    @classmethod
    def get_balanced_config(cls) -> 'RewardConfig':
        """Balanced configuration for throughput + fairness."""
        return cls(
            w_rate=1.0,
            w_goal=0.3,
            w_fair=0.3,      # Higher fairness weight
            w_time=0.02
        )
    
    @classmethod
    def get_exploration_config(cls) -> 'RewardConfig':
        """Configuration for exploration and user coverage."""
        return cls(
            w_rate=0.8,
            w_goal=0.4,      # Higher goal weight
            w_fair=0.4,      # Higher fairness weight  
            w_time=0.05      # Higher time pressure
        )


class RewardCalculator:
    """
    Reward calculation logic for UAV environment.
    
    This class implements the actual reward computation based on the configuration.
    It maintains internal state for incremental potential function shaping.
    """
    
    def __init__(self, config: RewardConfig):
        """Initialize reward calculator with configuration."""
        self.config = config
        self.previous_distance_to_end = None
        self.user_cumulative_service = {}
        self._prev_fair_utility = 0.0
        # è®¿é—®è¡°å‡æœºåˆ¶çŠ¶æ€
        self.user_visit_decay = {}  # {user_id: decay_factor}
        self.has_reached_end = False
        # ç”¨æˆ·ä¸“æ³¨ä¸è®¿é—®çŠ¶æ€ (æ”¹è¿›ç‰ˆ)
        self.current_focus_user = None  # å½“å‰ä¸“æ³¨çš„ç”¨æˆ·ID
        self.visited_users = set()       # å·²è®¿é—®å®Œæˆçš„ç”¨æˆ·
        self.user_completion_given = set()  # å·²å‘æ”¾ä¸€æ¬¡æ€§å®Œæˆå¥–åŠ±çš„ç”¨æˆ·
        self.prev_focus_distance = None  # ä¸Šä¸€æ­¥åˆ°ä¸“æ³¨ç”¨æˆ·çš„è·ç¦»ï¼ˆç”¨äºåŠ¿å‡½æ•°å¢é‡ï¼‰
        
        # æ–°å¢ï¼šè·ç¦»+æ—¶é—´è®¿é—®çŠ¶æ€è·Ÿè¸ª
        self.user_close_time = {}        # æ¯ä¸ªç”¨æˆ·åœ¨è®¿é—®è·ç¦»å†…çš„ç´¯ç§¯æ—¶é—´
        self.all_users_visited = False   # æ˜¯å¦æ‰€æœ‰ç”¨æˆ·éƒ½å·²è®¿é—®å®Œæˆ
    
    def reset(self, num_users: int):
        """Reset internal state for new episode."""
        self.previous_distance_to_end = None
        self.user_cumulative_service = {i: 0.0 for i in range(num_users)}
        self._prev_fair_utility = 0.0
        # é‡ç½®è®¿é—®è¡°å‡çŠ¶æ€
        self.user_visit_decay = {i: 1.0 for i in range(num_users)}  # åˆå§‹æ— è¡°å‡
        # é‡ç½®ç”¨æˆ·ä¸“æ³¨/è®¿é—®çŠ¶æ€ (æ”¹è¿›ç‰ˆ)
        self.current_focus_user = None
        self.visited_users = set()
        self.user_completion_given = set()
        self.prev_focus_distance = None
        
        # é‡ç½®è·ç¦»+æ—¶é—´è®¿é—®çŠ¶æ€
        self.user_close_time = {i: 0.0 for i in range(num_users)}
        self.all_users_visited = False
        
        # é‡ç½®ä½ç½®è®°å½•ï¼ˆç”¨äºç§»åŠ¨æ£€æµ‹ï¼‰
        self.prev_uav_position = None
    
    def potential_function(self, distance_to_end: float) -> float:
        """Potential function: F(d) = 1/(1 + d/d0)"""
        return 1.0 / (1.0 + distance_to_end / self.config.distance_normalization)
    
    def focus_potential_function(self, distance_to_focus_user: float) -> float:
        """ä¸“æ³¨è·ç¦»åŠ¿å‡½æ•°: F(d) = 1/(1 + d/d0)"""
        return 1.0 / (1.0 + distance_to_focus_user / self.config.focus_distance_normalization)
    
    def check_all_users_visited(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç”¨æˆ·éƒ½å·²è¢«å……åˆ†è®¿é—®"""
        if not self.config.enable_visit_gating:
            return True
        
        # ä½¿ç”¨ä¸“æ³¨æœºåˆ¶çš„ visited_users é›†åˆæ¥åˆ¤æ–­ï¼ˆæ›´ç²¾ç¡®ï¼‰
        if self.config.enable_user_focus:
            total_users = len(self.user_cumulative_service)
            return len(self.visited_users) >= total_users
        else:
            # å¦‚æœæ²¡æœ‰ä¸“æ³¨æœºåˆ¶ï¼Œå›é€€åˆ°åŸæ¥çš„æœåŠ¡é˜ˆå€¼æ£€æŸ¥
            for user_id in self.user_cumulative_service:
                if self.user_cumulative_service[user_id] < self.config.min_visit_threshold:
                    return False
            return True
    
    def _get_user_distance(self, uav_position, user_id: int, user_positions) -> float:
        """è®¡ç®—UAVä¸æŒ‡å®šç”¨æˆ·çš„äºŒç»´è·ç¦»"""
        import numpy as np
        if user_positions is None or user_id >= len(user_positions):
            return float('inf')
        return float(np.linalg.norm(uav_position[:2] - user_positions[user_id][:2]))

    def _select_nearest_unvisited(self, uav_position, user_positions) -> int:
        best_id, best_dist = -1, float('inf')
        for uid in range(len(user_positions)):
            if uid in self.visited_users:
                continue
            d = self._get_user_distance(uav_position, uid, user_positions)
            if d < best_dist:
                best_dist, best_id = d, uid
        return best_id

    def _update_user_focus(self, uav_position, user_positions):
        """æ”¹è¿›ç‰ˆä¸“æ³¨æœºåˆ¶ï¼šæ£€æŸ¥æœªè®¿é—®ç”¨æˆ·åˆ—è¡¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ç»ˆç‚¹å¯¼å‘æ¨¡å¼"""
        if not self.config.enable_user_focus:
            return
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªè®¿é—®ç”¨æˆ·
        unvisited_users = [uid for uid in range(len(user_positions)) if uid not in self.visited_users]
        
        if not unvisited_users:
            # æ‰€æœ‰ç”¨æˆ·éƒ½å·²è®¿é—®å®Œæˆ - åˆ‡æ¢åˆ°ç»ˆç‚¹å¯¼å‘æ¨¡å¼
            if not self.all_users_visited:
                print("ğŸ¯ æ‰€æœ‰ç”¨æˆ·è®¿é—®å®Œæˆï¼åˆ‡æ¢åˆ°ç»ˆç‚¹å¯¼å‘æ¨¡å¼")
                self.all_users_visited = True
                self.current_focus_user = None  # æ¸…ç©ºä¸“æ³¨ç”¨æˆ·
            return
        
        # è¿˜æœ‰æœªè®¿é—®ç”¨æˆ· - é€‰æ‹©æœ€è¿‘çš„æœªè®¿é—®ç”¨æˆ·ä½œä¸ºä¸“æ³¨ç›®æ ‡
        if self.current_focus_user is None or self.current_focus_user in self.visited_users:
            next_uid = self._select_nearest_unvisited(uav_position, user_positions)
            if next_uid != -1:
                old_focus = self.current_focus_user
                self.current_focus_user = next_uid
                self.prev_focus_distance = None  # é‡ç½®è·ç¦»åŠ¿å‡½æ•°
                print(f"ä¸“æ³¨åˆ‡æ¢: {old_focus} -> ç”¨æˆ·{next_uid}")
    
    def get_user_focus_multipliers(self, num_users: int) -> Dict[int, float]:
        """è·å–æ¯ä¸ªç”¨æˆ·çš„ä¸“æ³¨å¥–åŠ±å€æ•°ï¼ˆä¸“æ³¨=1.0ï¼Œæœªä¸“æ³¨=0.0ï¼Œå·²è®¿é—®=0.0ï¼‰"""
        if not self.config.enable_user_focus:
            return {i: 1.0 for i in range(num_users)}

        multipliers: Dict[int, float] = {}
        for user_id in range(num_users):
            if hasattr(self, 'visited_users') and user_id in self.visited_users:
                multipliers[user_id] = self.config.visited_user_reward_multiplier  # 0.0
            elif user_id == self.current_focus_user:
                multipliers[user_id] = self.config.focus_reward_multiplier        # 1.0
            else:
                multipliers[user_id] = self.config.non_focus_reward_multiplier    # 0.0

        return multipliers
    
    def _update_visit_decay(self, uav_position, user_individual_throughputs):
        """æ›´æ–°ç”¨æˆ·è®¿é—®è¡°å‡çŠ¶æ€ - ä¸ªä½“åŒ–è®¿é—®çŠ¶æ€ç®¡ç†"""
        import numpy as np
        
        # ä¸ªä½“åŒ–è®¿é—®çŠ¶æ€ç®¡ç†ï¼šåªå¯¹å·²å……åˆ†æœåŠ¡çš„ç”¨æˆ·è¡°å‡
        for user_id, throughput in enumerate(user_individual_throughputs):
            if user_id in self.user_cumulative_service:
                # å¦‚æœè¯¥ç”¨æˆ·ç´¯ç§¯æœåŠ¡è¶…è¿‡é˜ˆå€¼ï¼Œæ ‡è®°ä¸º"å·²è®¿é—®"å¹¶è¡°å‡è‡³æ¥è¿‘0
                if self.user_cumulative_service[user_id] > self.config.visit_decay_threshold:
                    # å¯¹å·²è®¿é—®ç”¨æˆ·ï¼šè¡°å‡è‡³æ¥è¿‘0ï¼ˆå‡ ä¹æ— å¥–åŠ±ï¼‰
                    self.user_visit_decay[user_id] = 0.00  # ä¿ç•™5%é¿å…å®Œå…¨ä¸º0
                # å¯¹æœªè®¿é—®ç”¨æˆ·ï¼šä¿æŒæ»¡å¥–åŠ±
                else:
                    self.user_visit_decay[user_id] = 1.0
    
    def _check_user_visit_completion(self, uav_position, user_positions, time_step: float):
        """æ£€æŸ¥ç”¨æˆ·è®¿é—®å®Œæˆæ¡ä»¶ï¼šè·ç¦»+æ—¶é—´åŒé‡è¦æ±‚"""
        if not self.config.enable_user_focus or user_positions is None:
            return
        
        # æ›´æ–°æ¯ä¸ªç”¨æˆ·çš„åœ¨èŒƒå›´å†…æ—¶é—´
        for user_id in range(len(user_positions)):
            if user_id in self.visited_users:
                continue  # è·³è¿‡å·²è®¿é—®å®Œæˆçš„ç”¨æˆ·
                
            distance = self._get_user_distance(uav_position, user_id, user_positions)
            
            if distance <= self.config.visit_distance_threshold:
                # UAVåœ¨è®¿é—®è·ç¦»å†…ï¼Œç´¯ç§¯æ—¶é—´
                self.user_close_time[user_id] += time_step
                
                # æ£€æŸ¥æ˜¯å¦æ»¡è¶³æ—¶é—´è¦æ±‚
                if self.user_close_time[user_id] >= self.config.visit_time_threshold:
                    if user_id not in self.visited_users:
                        print(f"âœ… ç”¨æˆ·{user_id}è®¿é—®å®Œæˆï¼è·ç¦»={distance:.1f}m, åœç•™æ—¶é—´={self.user_close_time[user_id]:.1f}s")
                        self.visited_users.add(user_id)
                        return user_id  # è¿”å›åˆšå®Œæˆçš„ç”¨æˆ·ID
            else:
                # UAVç¦»å¼€è®¿é—®èŒƒå›´ï¼Œé‡ç½®è®¡æ—¶ï¼ˆå¯é€‰ï¼šä¿æŒç´¯ç§¯æˆ–é‡ç½®ï¼‰
                # è¿™é‡Œé€‰æ‹©é‡ç½®ï¼Œè¦æ±‚è¿ç»­åœç•™
                if self.user_close_time[user_id] > 0:
                    self.user_close_time[user_id] = 0.0
        
        return None
    
    def calculate_reward(self, 
                        current_throughput: float,
                        uav_position,
                        end_position,
                        user_individual_throughputs,
                        user_positions=None,
                        time_step: float = 0.1) -> tuple[float, Dict[str, Any]]:
        """
        Calculate reward based on current state.
        
        Returns:
            Tuple of (total_reward, reward_breakdown)
        """
        import numpy as np
        
        # 1. æ”¹è¿›ç‰ˆç”¨æˆ·ä¸“æ³¨æœºåˆ¶ï¼šè·ç¦»+æ—¶é—´åŒé‡è®¿é—®åˆ¤å®š
        completion_bonus = 0.0
        distance_approach_reward = 0.0
        
        if self.config.enable_user_focus and user_positions is not None:
            # é¦–å…ˆæ£€æŸ¥ç”¨æˆ·è®¿é—®å®Œæˆæ¡ä»¶ï¼ˆè·ç¦»+æ—¶é—´ï¼‰
            completed_user = self._check_user_visit_completion(uav_position, user_positions, time_step)
            
            if completed_user is not None:
                # å‘æ”¾ä¸€æ¬¡æ€§å®Œæˆå¥–åŠ±
                if completed_user not in self.user_completion_given:
                    completion_bonus = self.config.per_user_completion_bonus
                    self.user_completion_given.add(completed_user)
                    print(f"ğŸ‰ ç”¨æˆ·{completed_user}å®Œæˆå¥–åŠ±å‘æ”¾: {completion_bonus:.1f}")
            
            # æ›´æ–°ä¸“æ³¨ç”¨æˆ·é€‰æ‹©ï¼ˆæ£€æŸ¥æ˜¯å¦åˆ‡æ¢åˆ°ç»ˆç‚¹å¯¼å‘æ¨¡å¼ï¼‰
            self._update_user_focus(uav_position, user_positions)
            
            # è®¡ç®—è·ç¦»æ¥è¿‘å¥–åŠ±ï¼ˆç±»ä¼¼w_rateçš„é‡è¦æ€§ï¼‰
            if self.current_focus_user is not None and not self.all_users_visited:
                current_focus_distance = self._get_user_distance(uav_position, self.current_focus_user, user_positions)
                
                if self.prev_focus_distance is not None:
                    # è·ç¦»å¢é‡å¥–åŠ±ï¼šF(d_prev) - F(d_curr)ï¼Œé è¿‘æ—¶ä¸ºæ­£å¥–åŠ±
                    F_prev = self.focus_potential_function(self.prev_focus_distance)
                    F_curr = self.focus_potential_function(current_focus_distance)
                    distance_approach_reward = self.config.w_distance_approach * (F_curr - F_prev)
                
                self.prev_focus_distance = current_focus_distance

        # è®¿é—®è¡°å‡ï¼šä¸ä½ç½®æ— å…³
        if self.config.enable_visit_decay and len(user_individual_throughputs) > 0:
            self._update_visit_decay(uav_position, user_individual_throughputs)
        
        # 2. ååé‡å¥–åŠ± (æ¡ä»¶æ€§ç»™äºˆï¼Œé¿å…hoveré™·é˜±)
        throughput_reward = 0.0
        normalized_throughput = 0.0
        
        # åªæœ‰åœ¨ç§»åŠ¨ä¸”é è¿‘ä¸“æ³¨ç”¨æˆ·æ—¶æ‰ç»™äºˆååé‡å¥–åŠ±
        if not self.all_users_visited and self.current_focus_user is not None and user_positions is not None:
            focus_distance = self._get_user_distance(uav_position, self.current_focus_user, user_positions)
            
            # æ£€æŸ¥æ˜¯å¦ç§»åŠ¨ï¼ˆæ¯”è¾ƒä¸ä¸Šä¸€æ­¥çš„è·ç¦»å·®ï¼‰
            moved_this_step = True
            if hasattr(self, 'prev_uav_position') and self.prev_uav_position is not None:
                displacement = np.linalg.norm(uav_position - self.prev_uav_position)
                moved_this_step = displacement > 1e-3  # ç§»åŠ¨é˜ˆå€¼1mm
            
            # åªæœ‰ç§»åŠ¨ä¸”åœ¨åˆç†è·ç¦»å†…æ‰ç»™äºˆååé‡å¥–åŠ±
            if moved_this_step and focus_distance < 30.0:
                if self.config.enable_user_focus and len(user_individual_throughputs) > 0:
                    focus_multipliers = self.get_user_focus_multipliers(len(user_individual_throughputs))
                    adjusted_throughput = 0.0
                    for user_id, user_throughput in enumerate(user_individual_throughputs):
                        focus_factor = focus_multipliers.get(user_id, 1.0)
                        adjusted_throughput += user_throughput * focus_factor
                    
                    normalized_throughput = np.clip(
                        adjusted_throughput / self.config.max_expected_throughput, 0.0, 1.0
                    )
                    # ç§»åŠ¨å¥–åŠ±å€æ•°ï¼šé¼“åŠ±æŒç»­ç§»åŠ¨
                    movement_multiplier = min(displacement / 5.0, 1.0) if hasattr(self, 'prev_uav_position') and self.prev_uav_position is not None else 1.0
                    throughput_reward = self.config.w_rate * normalized_throughput * movement_multiplier
        
        # è®°å½•å½“å‰ä½ç½®ä¾›ä¸‹æ¬¡æ¯”è¾ƒ
        self.prev_uav_position = uav_position.copy()
        
        # 3. Mission progress reward (potential function increment) with visit gating
        current_distance = np.linalg.norm(uav_position - end_position)
        
        if self.previous_distance_to_end is not None:
            # Potential function shaping: Î³F(s') - F(s)
            F_current = self.potential_function(current_distance)
            F_previous = self.potential_function(self.previous_distance_to_end)
            potential_increment = F_current - F_previous
            
            # Apply visit gating: ZERO goal reward until all users visited
            if self.config.enable_visit_gating:
                all_visited = self.check_all_users_visited()
                if all_visited:
                    # æ‰€æœ‰ç”¨æˆ·è®¿é—®å®Œæˆåï¼Œç»™äºˆå¼ºçƒˆçš„ç›®æ ‡å¥–åŠ±
                    goal_reward = self.config.w_goal * self.config.visited_goal_multiplier * potential_increment
                else:
                    # æœªè®¿é—®å®Œæ‰€æœ‰ç”¨æˆ·å‰ï¼Œç›®æ ‡å¥–åŠ±å®Œå…¨ä¸º0
                    goal_reward = 0.0
            else:
                goal_reward = self.config.w_goal * potential_increment
        else:
            goal_reward = 0.0  # No increment for first step
        
        self.previous_distance_to_end = current_distance
        
        # 4. Fairness reward (ç»ˆç‚¹å¯¼å‘æ¨¡å¼ä¸‹å…³é—­)
        fair_reward = 0.0
        if not self.all_users_visited and len(user_individual_throughputs) > 0:
            # åªåœ¨ç”¨æˆ·è®¿é—®é˜¶æ®µè®¡ç®—å…¬å¹³æ€§å¥–åŠ±
            fair_utilities = [
                np.log(self.config.fairness_epsilon + service) 
                for service in self.user_cumulative_service.values()
            ]
            fair_utility_curr = float(np.sum(fair_utilities))
            fair_reward = self.config.w_fair * (fair_utility_curr - self._prev_fair_utility)
            self._prev_fair_utility = fair_utility_curr
        
        # 5. Time penalty (gentle)
        time_penalty = -self.config.w_time * time_step
        
        # Terminal bonus if reaching end for the first time (only if all users visited)
        reached_end = current_distance < self.config.end_position_tolerance
        if reached_end and self.config.enable_visit_gating:
            all_visited = self.check_all_users_visited()
            terminal_bonus = self.config.terminal_bonus if all_visited else 0.0
        elif reached_end:
            terminal_bonus = self.config.terminal_bonus
        else:
            terminal_bonus = 0.0

        # 6. æ”¹è¿›ç‰ˆå¥–åŠ±åˆæˆï¼šåŒé˜¶æ®µè®¾è®¡
        if self.all_users_visited:
            # ç»ˆç‚¹å¯¼å‘é˜¶æ®µï¼šåªæœ‰ç›®æ ‡å¥–åŠ±ã€æ—¶é—´æƒ©ç½šå’Œç»ˆç«¯å¥–åŠ±
            total_reward = goal_reward + time_penalty + terminal_bonus
            print(f"ğŸ¯ ç»ˆç‚¹å¯¼å‘æ¨¡å¼ï¼šç›®æ ‡å¥–åŠ±={goal_reward:.3f}, æ—¶é—´æƒ©ç½š={time_penalty:.3f}")
        else:
            # ç”¨æˆ·è®¿é—®é˜¶æ®µï¼šååé‡ã€è·ç¦»æ¥è¿‘ã€å®Œæˆå¥–åŠ±ã€å…¬å¹³æ€§ã€æ—¶é—´æƒ©ç½š
            goal_penalty = 0.0
            # å¦‚æœUAVåœ¨å‘ç»ˆç‚¹ç§»åŠ¨ï¼Œæ–½åŠ è½»å¾®ç›®æ ‡æƒ©ç½š
            if hasattr(self, 'previous_distance_to_end') and self.previous_distance_to_end is not None:
                if current_distance < self.previous_distance_to_end:  # Moving towards goal
                    goal_penalty = -2.0  # è½»å¾®æƒ©ç½šï¼šé¼“åŠ±å…ˆè®¿é—®ç”¨æˆ·
            
            # æ·»åŠ hoveræƒ©ç½š
            hover_penalty = 0.0
            if hasattr(self, 'prev_uav_position') and self.prev_uav_position is not None:
                displacement = np.linalg.norm(uav_position - self.prev_uav_position)
                if displacement < 1e-3:  # åŸºæœ¬æ²¡ç§»åŠ¨
                    hover_penalty = -self.config.hover_penalty
            
            total_reward = throughput_reward + distance_approach_reward + completion_bonus + fair_reward + time_penalty + goal_penalty + hover_penalty
        
        # Detailed breakdown for debugging/analysis
        reward_breakdown = {
            'throughput_reward': float(throughput_reward),
            'distance_approach_reward': float(distance_approach_reward),
            'completion_bonus': float(completion_bonus),
            'goal_reward': float(goal_reward),
            'fair_reward': float(fair_reward),
            'time_penalty': float(time_penalty),
            'hover_penalty': float(hover_penalty) if 'hover_penalty' in locals() else 0.0,
            'terminal_bonus': float(terminal_bonus),
            'total_reward': float(total_reward),
            'normalized_throughput': float(normalized_throughput),
            'distance_to_end': float(current_distance),
            'cumulative_services': dict(self.user_cumulative_service),
            'current_focus_user': int(self.current_focus_user) if (self.config.enable_user_focus and self.current_focus_user is not None) else None,
            'visited_users': list(self.visited_users) if hasattr(self, 'visited_users') else [],
            'focus_distance': float(self.prev_focus_distance) if self.prev_focus_distance is not None else None,
            'all_users_visited': bool(self.all_users_visited),
            'user_close_time': dict(self.user_close_time) if hasattr(self, 'user_close_time') else {},
            'uav_moved': bool(locals().get('moved_this_step', True)),
            'displacement': float(locals().get('displacement', 0.0))
        }
        
        return float(total_reward), reward_breakdown
